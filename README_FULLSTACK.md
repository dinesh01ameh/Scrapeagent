# SwissKnife AI Scraper - Full-Stack Platform ğŸ”§ğŸ¤–

An intelligent, full-stack AI-powered web scraping platform that adapts to any website structure and extracts data with unprecedented accuracy and efficiency. Features a modern React dashboard for intuitive project management and real-time monitoring.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Node.js 16+ and npm
- Docker (optional)
- Ollama (for local LLM support)

### Full-Stack Development

1. **Clone the repository:**
```bash
git clone <repository-url>
cd swissknife-ai-scraper
```

2. **Install all dependencies:**
```bash
make install           # Backend dependencies
make install-frontend  # Frontend dependencies
```

3. **Start the full-stack application:**
```bash
make fullstack  # Starts both backend (port 8601) and frontend (port 8650)
```

Or start services individually:
```bash
make dev       # Backend API at http://localhost:8601
make frontend  # Frontend dashboard at http://localhost:8650
```

### Using Docker (Recommended)

**One-Command Launch:**
```bash
# Complete full-stack launch with interactive setup
make docker-launch

# Or specific environments
make docker-dev    # Development with hot reload
make docker-prod   # Production optimized
```

**Manual Docker Compose:**
```bash
# Build and run full-stack with Docker Compose
make docker-up

# Or use Docker Compose directly
docker-compose up --build -d
```

**Access URLs:**
- Frontend: http://localhost:8650
- Backend API: http://localhost:8601
- API Docs: http://localhost:8601/docs
- PostgreSQL: localhost:5432
- Redis: localhost:6379

## ğŸ¯ Features

### Frontend Dashboard
- **Modern React Interface**: TypeScript + Material-UI components
- **Authentication System**: Secure login/register with JWT tokens
- **Project Management**: Create, edit, and organize scraping projects
- **Real-time Dashboard**: Live statistics and activity monitoring
- **Responsive Design**: Mobile-friendly interface
- **State Management**: Redux Toolkit + React Query for optimal performance

### Backend Capabilities
- **Adaptive Extraction**: Automatically adapts to any website structure
- **AI-Powered Intelligence**: Uses local LLMs for content understanding
- **Natural Language Interface**: Describe what you want to scrape in plain English
- **Multi-Modal Processing**: Handles text, images, PDFs, videos, and more
- **Proxy Rotation**: Advanced proxy management with health monitoring
- **Database Integration**: PostgreSQL/Supabase with comprehensive schema

### Technical Features
- **FastAPI Backend**: High-performance async API with 25+ endpoints
- **React Frontend**: Modern TypeScript application with 20+ components
- **Intelligent Fallbacks**: CSS â†’ XPath â†’ Regex â†’ LLM extraction strategies
- **Comprehensive Testing**: 80+ tests with 100% pass rate
- **Docker Support**: Full containerization with multi-service setup
- **Health Monitoring**: Built-in health checks and system monitoring
- **Extensible Architecture**: Plugin-ready design for custom extractors

## ğŸ“– Documentation

- [Frontend Dashboard](http://localhost:8650) - React web interface
- [API Documentation](http://localhost:8601/docs) - Interactive Swagger UI
- [Project Status](Docs/project_status.md) - Current development status
- [Comprehensive Project Plan](Docs/COMPREHENSIVE_PROJECT_PLAN.md) - Detailed roadmap

## ğŸ› ï¸ Development

### Available Commands

```bash
# Full-Stack Development
make fullstack       # Start both backend and frontend
make install-frontend # Install frontend dependencies
make frontend        # Start frontend development server
make build-frontend  # Build frontend for production

# Backend Development
make dev            # Start backend development server
make test           # Run all tests
make lint           # Run code linting
make format         # Format code

# Docker (Complete Containerization)
make docker-launch  # Interactive full-stack launch
make docker-dev     # Development environment with hot reload
make docker-prod    # Production environment
make docker-build   # Build Docker images
make docker-up      # Start with Docker Compose
make docker-down    # Stop Docker containers
make docker-logs    # View container logs
make docker-status  # Check service status
make docker-clean   # Clean up containers and volumes

# Utilities
make clean          # Clean temporary files
make health         # Check system health
make setup-ollama   # Setup Ollama with models
```

### Project Structure

```
swissknife-ai-scraper/
â”œâ”€â”€ frontend/            # React TypeScript dashboard
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/       # Page components
â”‚   â”‚   â”œâ”€â”€ services/    # API service layer
â”‚   â”‚   â”œâ”€â”€ store/       # Redux store and slices
â”‚   â”‚   â””â”€â”€ types/       # TypeScript definitions
â”‚   â”œâ”€â”€ public/          # Static assets
â”‚   â””â”€â”€ package.json     # Frontend dependencies
â”œâ”€â”€ api/                 # FastAPI routes and endpoints
â”œâ”€â”€ core/                # Core scraping engine
â”œâ”€â”€ features/            # Advanced features (NLP, multimodal, etc.)
â”œâ”€â”€ database/            # Database schema and repositories
â”œâ”€â”€ services/            # Business logic services
â”œâ”€â”€ config/              # Configuration management
â”œâ”€â”€ utils/               # Utility functions and helpers
â”œâ”€â”€ tests/               # Comprehensive test suite
â”œâ”€â”€ docker/              # Docker configuration
â”œâ”€â”€ scripts/             # Utility scripts
â””â”€â”€ Docs/                # Documentation
```

## ğŸ”§ Configuration

### Backend Configuration
Copy `.env.example` to `.env` and adjust as needed:

```bash
# API Configuration
API_HOST=0.0.0.0
API_PORT=8601
DEBUG=true

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/swissknife
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key

# LLM Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=llama2

# Proxy Configuration
PROXY_ENABLED=false
PROXY_ROTATION_ENABLED=false
```

### Frontend Configuration
Copy `frontend/.env.example` to `frontend/.env`:

```bash
# API Configuration
REACT_APP_API_URL=http://localhost:8601

# Environment
REACT_APP_ENV=development
```

## ğŸ“Š Performance

- **Processing Speed**: 447+ queries/second
- **Response Time**: Sub-millisecond for cached requests
- **Memory Usage**: Optimized for low memory footprint
- **Concurrent Requests**: Handles 1000+ concurrent connections
- **Success Rate**: >95% extraction accuracy across diverse websites
- **Frontend Performance**: Optimized React app with code splitting and caching

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Backend tests
make test

# Frontend tests
cd frontend && npm test

# Run specific test categories
python -m pytest tests/test_core.py -v
python -m pytest tests/test_features.py -v
python -m pytest tests/test_api.py -v
```

## ğŸ³ Docker Deployment

### Development
```bash
docker-compose up -d
# Frontend: http://localhost:8650
# Backend: http://localhost:8601
# PostgreSQL: localhost:5432
```

### Production
```bash
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ¨ User Interface

The React dashboard provides:

- **Dashboard**: Real-time statistics and activity monitoring
- **Projects**: Create and manage scraping projects
- **Jobs**: Monitor scraping jobs with live status updates
- **Content**: Browse and analyze extracted content
- **Settings**: User profile and system preferences

## ğŸ“Š Project Status

### âœ… Completed (Phase 1 & 2)
- **Backend**: Complete FastAPI application with all core features
- **Frontend**: Complete React dashboard with authentication and project management
- **Database**: PostgreSQL/Supabase integration with comprehensive schema
- **AI Features**: Natural language interface, multimodal processing, proxy rotation
- **Testing**: 80+ comprehensive tests with 100% pass rate
- **Documentation**: Comprehensive guides and API documentation

### ğŸ¯ Next Phase (Phase 3)
- Advanced job management with real-time monitoring
- Content browser with search and filtering
- Natural language query interface
- Analytics and reporting dashboard
- Production monitoring and alerting

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

### Backend
- Built with [FastAPI](https://fastapi.tiangolo.com/)
- AI powered by [Ollama](https://ollama.ai/)
- Database with [PostgreSQL](https://postgresql.org/) and [Supabase](https://supabase.com/)
- Testing with [pytest](https://pytest.org/)

### Frontend
- Built with [React](https://reactjs.org/) and [TypeScript](https://typescriptlang.org/)
- UI components by [Material-UI](https://mui.com/)
- State management with [Redux Toolkit](https://redux-toolkit.js.org/)
- Data fetching with [React Query](https://react-query.tanstack.com/)

---

**SwissKnife AI Scraper** - Making web scraping intelligent, adaptive, and effortless with a modern full-stack interface.
